{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/CS/pvp0001/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/CS/pvp0001/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fasttext as ft\n",
    "import faiss\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"/raid/Praveen_Stuff/Eluvio_DS_Challenge.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dir_name)\n",
    "ids = list()\n",
    "length = df.shape[0]\n",
    "x = 1\n",
    "for i in range(length):\n",
    "    ids.append(x)\n",
    "    x+=1\n",
    "df['unique_id'] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_path = \"idx_processed_appended.txt\"\n",
    "titles_path = \"title_processed_appended.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train fastText Model\n",
    "embedding_dim = 100\n",
    "window_size = 5\n",
    "min_word_count = 5\n",
    "EPOCH = 25\n",
    "model_name = \"ft_model_em100_ws5_mwc5_ep25_preprocessed_appended.bin\"\n",
    "# Uncomment,if you want to train the fast text model\n",
    "# ft_model = ft.train_unsupervised(input=titles_path, dim=embedding_dim, epoch=EPOCH, model=\"skipgram\")\n",
    "# Uncomment,if you want to save the fast text model\n",
    "# ft_model.save_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "#Load the fastText model\n",
    "ft_model = ft.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the title and other information which was stored in text file after preprocessing\n",
    "desc_file = open(titles_path, 'r')\n",
    "id_file = open(ids_path, 'r')\n",
    "desc_Lines = desc_file.readlines()\n",
    "id_lines = id_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the embeddings using fastText trained model\n",
    "job_id_list = list()\n",
    "embedding_list = list()\n",
    "i = 0\n",
    "for job_id,job_desc in zip(id_lines,desc_Lines):\n",
    "    embedding = ft_model.get_sentence_vector(job_desc.rstrip())\n",
    "    #embedding_dict[int(job_id)] = embedding\n",
    "    job_id_list.append(int(job_id))\n",
    "    embedding_list.append(embedding)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to numpy arrays for easy of use\n",
    "embedding_list = np.asarray(embedding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(job_ids, embeddings, target_embedding, num_recs, vec_dim):\n",
    "    '''\n",
    "    Uses facebook FAISS library to perform L2 similarity search with 100-d vector embeddings\n",
    "    \n",
    "    job_ids: list of jobs_ids, whose indices correspond to embedding indices\n",
    "    embeddings: numpy array of 100-d vectors, whose indices correspond to the indices of job_ids\n",
    "    target_ids: list of target ids\n",
    "    num_recs: the number of recommendations to make\n",
    "    \n",
    "    returns: job dictionary with key = job id and value = embedding\n",
    "    '''\n",
    "    target_embeddings = list()\n",
    "    target_embeddings.append(target_embedding)\n",
    "    print(target_embeddings)\n",
    "    target_embeddings = np.asarray(target_embeddings)\n",
    "    index = faiss.IndexFlatL2(vec_dim)\n",
    "    index.add(embeddings)\n",
    "    D, I = index.search(target_embeddings, num_recs)\n",
    "    print(\"Finding the nearest neighbor of the following query: \")\n",
    "    similar_jobs = {}\n",
    "    #index is a list containing indexes corresponding to number of reccomendations requested\n",
    "    for index in I:\n",
    "        for element in index:\n",
    "            #print(\"\\n\\nA near neighbor is at index: \")\n",
    "            #print(element)\n",
    "            #print(\"And the element at this index in the db is: \")\n",
    "            #print(embeddings[element])\n",
    "            similar_jobs.update({job_ids[element]: embeddings[element]})\n",
    "            \n",
    "    print(type(similar_jobs))\n",
    "    return similar_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the keywords to give the recommendation\n",
    "keyword = \"Scores killed in Pakistan clashes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.04412896,  0.01168365, -0.11756157, -0.04418303,  0.00869185,\n",
      "       -0.05140894, -0.08847402,  0.00497872,  0.07584609,  0.04833292,\n",
      "       -0.09222653, -0.14014985,  0.08008041, -0.03641176, -0.08736008,\n",
      "        0.01132878, -0.05632193,  0.04506412,  0.04243913, -0.03035854,\n",
      "        0.03725669,  0.00509   ,  0.09948729,  0.09680115,  0.06472278,\n",
      "       -0.08910923, -0.05175205,  0.12667517,  0.00504389,  0.05516104,\n",
      "       -0.07658587, -0.12319257,  0.0264945 , -0.04150046, -0.00325571,\n",
      "        0.15404409, -0.03505963, -0.08807554, -0.05926043, -0.00561597,\n",
      "       -0.08183727,  0.07846905,  0.08858684,  0.04709188,  0.10663982,\n",
      "        0.03738658,  0.00309123,  0.06106735, -0.12260303, -0.11214973,\n",
      "        0.00052229,  0.02534869,  0.14247674, -0.04385375, -0.04842799,\n",
      "       -0.05981544, -0.01091424, -0.03362558, -0.10822722, -0.10855742,\n",
      "        0.06873065,  0.0324939 , -0.01225883,  0.07589256,  0.11653968,\n",
      "        0.14609708, -0.03977957,  0.0204637 ,  0.06170549, -0.06977635,\n",
      "       -0.0159138 , -0.02372053, -0.01629794, -0.03451617,  0.09993738,\n",
      "        0.05880789,  0.11413884, -0.01082396,  0.05482857,  0.05041862,\n",
      "       -0.01459216,  0.02932598,  0.02494889, -0.04159052, -0.03854658,\n",
      "       -0.06745411,  0.18473332, -0.07129223, -0.08870501,  0.03544443,\n",
      "       -0.01530859, -0.02069547, -0.10939903,  0.09158573,  0.07457689,\n",
      "        0.09609877,  0.02923772,  0.04676928, -0.09325257, -0.23931888],\n",
      "      dtype=float32)]\n",
      "Finding the nearest neighbor of the following query: \n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#Tokenize String\n",
    "tokenized_words = word_tokenize(keyword)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#Remove Stop words\n",
    "filtered_keyword = list()\n",
    "for w in tokenized_words:\n",
    "    if w not in stop_words: \n",
    "        filtered_keyword.append(w)\n",
    "#Stemming\n",
    "porter = PorterStemmer()\n",
    "stem_keyword = list()\n",
    "for word in filtered_keyword:\n",
    "    stem_keyword.append(porter.stem(word))\n",
    "    stem_keyword.append(\" \")\n",
    "stem_keyword = \"\".join(stem_keyword)\n",
    "# Create the embedding of the vector\n",
    "target_embedding = ft_model.get_sentence_vector(stem_keyword)\n",
    "similar_job_embeddings = recommend(job_id_list, embedding_list, target_embedding, 20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec_desc(similar_dict, column_name, df):\n",
    "    '''\n",
    "    Finds the recommendation based on similar_job_emebeddings \n",
    "    \n",
    "    similar_dict : Similar job embeddings\n",
    "    column_name : the name of the column in the dataframe where unique id matches\n",
    "    df: the dataframe of our work\n",
    "    returns : target dataframe and recommendation dataframe\n",
    "    '''\n",
    "    final_df = pd.DataFrame()\n",
    "    for target in similar_dict.keys():\n",
    "        target_df = df.loc[df[column_name] == target]\n",
    "        if(final_df.empty):\n",
    "            final_df = df.loc[df[column_name] == target]\n",
    "        else:\n",
    "            final_df = pd.concat([final_df, df.loc[df[column_name] == target]])\n",
    "    # Sort based on the number of up_votes\n",
    "    final_df = final_df.sort_values(by=['up_votes'], ascending=False)        \n",
    "    return target_df, final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df, recs_df = get_rec_desc(similar_job_embeddings, \"unique_id\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time_created date_created  up_votes  down_votes  \\\n",
      "329238    1418793563   2014-12-17       310           0   \n",
      "98185     1314462605   2011-08-27       143           0   \n",
      "361851    1429368168   2015-04-18        52           0   \n",
      "475784    1468068204   2016-07-09        33           0   \n",
      "289381    1405631866   2014-07-17        22           0   \n",
      "318927    1414938530   2014-11-02        16           0   \n",
      "115538    1330435758   2012-02-28        14           0   \n",
      "82864     1301849212   2011-04-03        13           0   \n",
      "261697    1394886754   2014-03-15        11           0   \n",
      "68634     1291631778   2010-12-06         8           0   \n",
      "47630     1262361411   2010-01-01         7           0   \n",
      "88084     1306591651   2011-05-28         7           0   \n",
      "318940    1414943261   2014-11-02         5           0   \n",
      "35974     1244405962   2009-06-07         5           0   \n",
      "100452    1316550508   2011-09-20         4           0   \n",
      "100410    1316531337   2011-09-20         4           0   \n",
      "220147    1381668524   2013-10-13         3           0   \n",
      "154101    1357940640   2013-01-11         1           0   \n",
      "499275    1476314479   2016-10-12         0           0   \n",
      "229058    1384606868   2013-11-16         0           0   \n",
      "\n",
      "                                                    title  over_18  \\\n",
      "329238  Pakistan airstrikes kill at least 22 militants...    False   \n",
      "98185   At least 25 police and soldiers have been kill...    False   \n",
      "361851  At least 33 people have been killed and 100 in...    False   \n",
      "475784  Kashmir protests LIVE: 8 killed, many injured ...    False   \n",
      "289381  At least 14 Tunisian soldiers have been killed...    False   \n",
      "318927  At least 37 killed after blast near Wagah Bord...    False   \n",
      "115538  Shiites killed in Pakistan bus ambush: At leas...    False   \n",
      "82864   Suicide attackers have killed at least 41 peop...    False   \n",
      "261697  Carnage in Nigeria - At least 40 people are ki...    False   \n",
      "68634   Dozens killed in Pakistan attack - A suicide b...    False   \n",
      "47630   Latest from Pakistan: At least 40 people have ...    False   \n",
      "88084   Deadly bomb blast hits Pakistan killing at lea...    False   \n",
      "318940  45 killed, over 70 injured in Pakistan s Lahor...    False   \n",
      "35974   Villagers in northwest Pakistan have attacked ...    False   \n",
      "100452  Dozens of Shia pilgrims shot in Pakistan: Unid...    False   \n",
      "100410  Pakistani Shia pilgrims killed in gun attack o...    False   \n",
      "220147  Indian stampede kills dozens of Hindu worshipp...    False   \n",
      "154101  Pakistani province in mourning after blasts ki...    False   \n",
      "499275  At least 36 people killed and over 86 injured ...    False   \n",
      "229058  Dozens dead in clash with Libyan militiamen in...    False   \n",
      "\n",
      "                     author   category  unique_id  \n",
      "329238            InfernoBA  worldnews     329239  \n",
      "98185            Ze_Carioca  worldnews      98186  \n",
      "361851      NinjaDiscoJesus  worldnews     361852  \n",
      "475784            uber1geek  worldnews     475785  \n",
      "289381        DoremusJessup  worldnews     289382  \n",
      "318927              reedlad  worldnews     318928  \n",
      "115538         slaterhearst  worldnews     115539  \n",
      "82864             epitaph25  worldnews      82865  \n",
      "261697           oshunsmall  worldnews     261698  \n",
      "68634               StoneMe  worldnews      68635  \n",
      "47630              nzeeshan  worldnews      47631  \n",
      "88084           splunge4me2  worldnews      88085  \n",
      "318940               Fudus2  worldnews     318941  \n",
      "35974             unclefred  worldnews      35975  \n",
      "100452               mjanes  worldnews     100453  \n",
      "100410        davidreiss666  worldnews     100411  \n",
      "220147           oshunsmall  worldnews     220148  \n",
      "154101  BackFromTheFuture12  worldnews     154102  \n",
      "499275       Fuck_Terrorism  worldnews     499276  \n",
      "229058        davidreiss666  worldnews     229059  \n"
     ]
    }
   ],
   "source": [
    "print(recs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praveen_tf",
   "language": "python",
   "name": "praveen_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
