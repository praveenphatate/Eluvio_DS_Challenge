{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/CS/pvp0001/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/CS/pvp0001/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import fasttext as ft\n",
    "import faiss\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from datetime import datetime, timedelta\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         time_created date_created  up_votes  down_votes  \\\n",
      "0         1201232046   2008-01-25         3           0   \n",
      "1         1201232075   2008-01-25         2           0   \n",
      "2         1201232523   2008-01-25         3           0   \n",
      "3         1201233290   2008-01-25         1           0   \n",
      "4         1201274720   2008-01-25         4           0   \n",
      "...              ...          ...       ...         ...   \n",
      "509231    1479816764   2016-11-22         5           0   \n",
      "509232    1479816772   2016-11-22         1           0   \n",
      "509233    1479817056   2016-11-22         1           0   \n",
      "509234    1479817157   2016-11-22         1           0   \n",
      "509235    1479817346   2016-11-22         1           0   \n",
      "\n",
      "                                                                                           title  \\\n",
      "0                                                              Scores killed in Pakistan clashes   \n",
      "1                                                               Japan resumes refuelling mission   \n",
      "2                                                                US presses Egypt on Gaza border   \n",
      "3                                                   Jump-start economy: Give health care to all    \n",
      "4                                                Council of Europe bashes EU&UN terror blacklist   \n",
      "...                                                                                          ...   \n",
      "509231   Heil Trump : Donald Trump s  alt-right  white nationalist supporters invoke Nazi salute   \n",
      "509232                       There are people speculating that this could be Madeleine McCann...   \n",
      "509233                                                 Professor receives Arab Researchers Award   \n",
      "509234                                   Nigel Farage attacks response to Trump ambassador tweet   \n",
      "509235                          Palestinian wielding knife shot dead in West Bank: Israel police   \n",
      "\n",
      "        over_18         author   category  \n",
      "0         False          polar  worldnews  \n",
      "1         False          polar  worldnews  \n",
      "2         False          polar  worldnews  \n",
      "3         False        fadi420  worldnews  \n",
      "4         False       mhermans  worldnews  \n",
      "...         ...            ...        ...  \n",
      "509231    False  nonamenoglory  worldnews  \n",
      "509232    False      SummerRay  worldnews  \n",
      "509233    False      AUSharjah  worldnews  \n",
      "509234    False    smilyflower  worldnews  \n",
      "509235    False     superislam  worldnews  \n",
      "\n",
      "[509236 rows x 8 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Reading .csv as pandas dataframe\n",
    "dir_name = \"/raid/Praveen_Stuff/Eluvio_DS_Challenge.csv\"\n",
    "df = pd.read_csv(dir_name)\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating unique id's for our data\n",
    "ids = list()\n",
    "length = df.shape[0]\n",
    "x = 1\n",
    "for i in range(length):\n",
    "    ids.append(x)\n",
    "    x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing unique ids to our dataframe\n",
    "df['unique_id'] = ids\n",
    "# Get the values of every column as a list\n",
    "ids = df['unique_id'].values.tolist()\n",
    "time_created = df['time_created'].values.tolist()\n",
    "date_created = df['date_created'].values.tolist()\n",
    "author = df['author'].values.tolist()\n",
    "titles =  df['title'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(titles):\n",
    "    '''\n",
    "    Function to remove stop words given a list of senetences.\n",
    "    \n",
    "    senetences : List of strings\n",
    "    \n",
    "    returns : List of List of strings\n",
    "    '''\n",
    "    # Tokenize the sentence\n",
    "    word_tokens = []\n",
    "    for each_title in titles:\n",
    "        word_token = word_tokenize(each_title) \n",
    "        word_tokens.append(word_token)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_sentences = []\n",
    "    for word_token in word_tokens:\n",
    "        filtered_sentence = [] \n",
    "        for w in word_token:\n",
    "            if w not in stop_words: \n",
    "                filtered_sentence.append(w) \n",
    "        filtered_sentences.append(filtered_sentence)\n",
    "    return filtered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentences = remove_stopwords(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemSentence(sentences):\n",
    "    '''\n",
    "    Function to stem sentences given a list of senetences.\n",
    "    \n",
    "    senetences : List of List of strings\n",
    "    \n",
    "    returns : List of sentences\n",
    "    '''\n",
    "    porter = PorterStemmer()\n",
    "    stem_sentences = []\n",
    "    for sentence in sentences:\n",
    "        stem_sentence=[]\n",
    "        for word in sentence:\n",
    "            stem_sentence.append(porter.stem(word))\n",
    "            stem_sentence.append(\" \")\n",
    "        stem_sentences.append(\"\".join(stem_sentence))\n",
    "    return stem_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_sentences = stemSentence(filtered_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japan say russian bomber violat it airspac - new york time \n"
     ]
    }
   ],
   "source": [
    "print(stem_sentences[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write to text\n",
    "# We are appending Time, Date, Author to title files\n",
    "def write_text(ids_path, titles_path, ids, titles, time_created, date_created, author):\n",
    "    '''\n",
    "    Function to write to a file\n",
    "    \n",
    "    ids_path : path with filename.txt to store unique id's\n",
    "    titles_path : path with filename.txt to store titles appended with time, date and author\n",
    "    id's: List of Unique id's, whose indices correspond to the indices of title\n",
    "    titles: List of Titles\n",
    "    time_created: List of time_created, whose indices correspond to the indices of title\n",
    "    date_created : List of date_created, whose indices correspond to the indices of title\n",
    "    author = List of author, whose indices correspond to the indices of title\n",
    "    \n",
    "    returns: None\n",
    "    '''\n",
    "    f1 = open(ids_path, 'w')\n",
    "    f2 = open(titles_path, 'w')\n",
    "    for i in range(length):\n",
    "        f1.write(str(ids[i]))\n",
    "        f1.write(\"\\n\")\n",
    "        f2.write(\"time: \")\n",
    "        f2.write(str(time_created[i]))\n",
    "        f2.write(\" \")\n",
    "        f2.write(\"date: \")\n",
    "        f2.write(str(date_created[i]))\n",
    "        f2.write(\" \")\n",
    "        f2.write(\"author: \")\n",
    "        f2.write(author[i])\n",
    "        f2.write(\" \")\n",
    "        f2.write(\"title: \")\n",
    "        f2.write(titles[i])\n",
    "        f2.write(\"\\n\")\n",
    "    f1.close()\n",
    "    f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_path = \"idx_processed_appended.txt\"\n",
    "titles_path = \"title_processed_appended.txt\"\n",
    "# Writes Id's and titles to the text file\n",
    "write_text(ids_path, titles_path, ids, stem_sentences, time_created, date_created, author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training an Fast Text model to create embeddings\n",
    "embedding_dim = 100\n",
    "window_size = 5\n",
    "min_word_count = 5\n",
    "EPOCH = 25\n",
    "model_name = \"ft_model_em100_ws5_mwc5_ep25_preprocessed_appended.bin\"\n",
    "# Uncomment,if you want to train the fast text model\n",
    "# ft_model = ft.train_unsupervised(input=titles_path, dim=embedding_dim, epoch=EPOCH, model=\"skipgram\")\n",
    "# Uncomment,if you want to save the fast text model\n",
    "# ft_model.save_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft_model = ft.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509236\n"
     ]
    }
   ],
   "source": [
    "# We are opening the unique id's and preprocessed_titles with time, date and author file\n",
    "desc_file = open(titles_path, 'r')\n",
    "id_file = open(ids_path, 'r')\n",
    "desc_Lines = desc_file.readlines()\n",
    "id_lines = id_file.readlines()\n",
    "print(len(id_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are creating the embedding matrix using the trained Fast text model\n",
    "job_id_list = list()\n",
    "embedding_list = list()\n",
    "i = 0\n",
    "for job_id,job_desc in zip(id_lines,desc_Lines):\n",
    "    embedding = ft_model.get_sentence_vector(job_desc.rstrip())\n",
    "    job_id_list.append(int(job_id))\n",
    "    embedding_list.append(embedding)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509236"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(job_ids, embeddings, target_ids, num_recs, vec_dim):\n",
    "    '''\n",
    "    Uses facebook FAISS library to perform L2 similarity search with 100-d vector embeddings\n",
    "    \n",
    "    job_ids: list of jobs_ids, whose indices correspond to embedding indices\n",
    "    embeddings: numpy array of 100-d vectors, whose indices correspond to the indices of job_ids\n",
    "    target_ids: list of target ids\n",
    "    num_recs: the number of recommendations to make\n",
    "    \n",
    "    returns: job dictionary with key = job id and value = embedding\n",
    "    '''\n",
    "    #Get the corresponding embeddings for each target ID\n",
    "    #and convert to numpy array for FAISS\n",
    "    queries = []\n",
    "    for tid in target_ids:\n",
    "        queries.append(embeddings[job_ids.index(tid)])\n",
    "    search_queries = np.asarray(queries)\n",
    "    #Brute force, L2 distance search index.\n",
    "    index = faiss.IndexFlatL2(vec_dim) #build the index\n",
    "    index.add(embeddings)\n",
    "    D, I = index.search(search_queries, num_recs)\n",
    "    print(\"Finding the nearest neighbor of the following query: \")\n",
    "    similar_jobs = {}\n",
    "    #index is a list containing indexes corresponding to number of reccomendations requested\n",
    "    for index in I:\n",
    "        for element in index:\n",
    "            similar_jobs.update({job_ids[element]: embeddings[element]})\n",
    "            \n",
    "    return similar_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.04222713, -0.03767658, -0.11204252, -0.03170907,  0.02707273,\n",
      "       -0.02723083, -0.0564267 , -0.00905808,  0.00707193,  0.0405337 ,\n",
      "       -0.04255448, -0.08341026,  0.0723864 , -0.07140297, -0.06992448,\n",
      "        0.03960486, -0.04777391,  0.01554316, -0.01983578, -0.02647545,\n",
      "        0.0443822 , -0.00086667,  0.06553064,  0.06683465,  0.03487814,\n",
      "       -0.01339015, -0.01525639,  0.09661102,  0.00549085,  0.05244684,\n",
      "       -0.10818604, -0.12197697,  0.03678501, -0.05858905,  0.00154539,\n",
      "        0.05988876, -0.01616365, -0.04995066,  0.0232853 , -0.06058578,\n",
      "       -0.04624536,  0.02377324,  0.01242548,  0.10018274,  0.08303244,\n",
      "        0.0265761 , -0.00770316, -0.02071305, -0.13202055, -0.05777887,\n",
      "       -0.09516828, -0.00798994,  0.04117286,  0.01577277,  0.00315286,\n",
      "        0.00434462, -0.00741288, -0.02544191, -0.07644507, -0.04221267,\n",
      "        0.03028675,  0.05331694, -0.00263942,  0.10309516,  0.11012197,\n",
      "        0.16074981,  0.01297159, -0.02167593,  0.0165487 , -0.08668431,\n",
      "        0.03515244, -0.01509922, -0.05928418, -0.05657744,  0.05265373,\n",
      "        0.0487429 ,  0.04961701, -0.00869006,  0.06560172,  0.00736941,\n",
      "       -0.06179783,  0.02295102,  0.05044229, -0.01355819, -0.03394418,\n",
      "       -0.12488419,  0.15995145, -0.01385355, -0.13673645,  0.05550235,\n",
      "       -0.05812522, -0.0610254 , -0.19156158,  0.06644813,  0.18915433,\n",
      "        0.13555826, -0.00839569,  0.07721428, -0.12012385, -0.15576404],\n",
      "      dtype=float32)]\n",
      "1\n",
      "Finding the nearest neighbor of the following query: \n"
     ]
    }
   ],
   "source": [
    "embedding_list = np.asarray(embedding_list)\n",
    "target_job_ids_list = [1]\n",
    "similar_job_embeddings = recommend(job_id_list, embedding_list, target_job_ids_list, 20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec_desc(similar_dict, column_name, df):\n",
    "    '''\n",
    "    Finds the recommendation based on similar_job_emebeddings \n",
    "    \n",
    "    similar_dict : Similar job embeddings\n",
    "    column_name : the name of the column in the dataframe where unique id matches\n",
    "    df: the dataframe of our work\n",
    "    returns : target dataframe and recommendation dataframe\n",
    "    '''\n",
    "    final_df = pd.DataFrame()\n",
    "    for target in similar_dict.keys():\n",
    "        target_df = df.loc[df[column_name] == target]\n",
    "        if(final_df.empty):\n",
    "            final_df = df.loc[df[column_name] == target]\n",
    "        else:\n",
    "            final_df = pd.concat([final_df, df.loc[df[column_name] == target]])\n",
    "    # Sort based on the number of up_votes\n",
    "    final_df = final_df.sort_values(by=['up_votes'], ascending=False)        \n",
    "    return target_df, final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df, recs_df = get_rec_desc(similar_job_embeddings, \"unique_id\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time_created date_created  up_votes  down_votes  \\\n",
      "277480    1400809678   2014-05-23       107           0   \n",
      "193619    1372620163   2013-06-30        74           0   \n",
      "215289    1379888846   2013-09-22        40           0   \n",
      "137482    1348238627   2012-09-21        14           0   \n",
      "263607    1395417454   2014-03-21        13           0   \n",
      "160561    1361056495   2013-02-16        13           0   \n",
      "38953     1246875680   2009-07-06         8           0   \n",
      "170699    1365008261   2013-04-03         4           0   \n",
      "118359    1333071968   2012-03-30         3           0   \n",
      "157457    1359587302   2013-01-30         3           0   \n",
      "0         1201232046   2008-01-25         3           0   \n",
      "404205    1444705867   2015-10-13         1           0   \n",
      "154101    1357940640   2013-01-11         1           0   \n",
      "333404    1420404408   2015-01-04         1           0   \n",
      "82277     1301322903   2011-03-28         1           0   \n",
      "426587    1451351897   2015-12-29         0           0   \n",
      "38923     1246863510   2009-07-06         0           0   \n",
      "153947    1357854375   2013-01-10         0           0   \n",
      "107624    1323183152   2011-12-06         0           0   \n",
      "180738    1368287224   2013-05-11         0           0   \n",
      "\n",
      "                                                          title  over_18  \\\n",
      "277480                           Airstrikes in Pakistan kill 60    False   \n",
      "193619                       49 killed in Pakistan bomb attacks    False   \n",
      "215289                       Pakistan church blast kills dozens    False   \n",
      "137482                        Pakistan Protests: Sixteen Killed    False   \n",
      "263607                   Scores killed in wave of Iraq bombings    False   \n",
      "160561               Huge Bomb Kills Dozens in Pakistani Market    False   \n",
      "38953                           Scores killed in China protests    False   \n",
      "170699                       Flooding kills dozens in Argentina    False   \n",
      "118359               Several killed in violence in Karachi \\r\\n    False   \n",
      "157457                           Nine dead in Pakistan violence    False   \n",
      "0                             Scores killed in Pakistan clashes    False   \n",
      "404205           Tunisian Troops Killed in Clash with Militants    False   \n",
      "154101  Pakistani province in mourning after blasts kill scores    False   \n",
      "333404                          Scores dead  in Burundi clashes    False   \n",
      "82277                Scores killed in Yemen arms factory blasts    False   \n",
      "426587                           Attacks Kill Scores in Nigeria    False   \n",
      "38923                 Scores Killed in Clashes in Western China    False   \n",
      "153947              Scores killed in multiple Pakistan bombings    False   \n",
      "107624       Rare Attacks on Shiites Kill Scores in Afghanistan    False   \n",
      "180738                             Blasts kill dozens in Turkey    False   \n",
      "\n",
      "                     author   category  unique_id  \n",
      "277480             Destione  worldnews     277481  \n",
      "193619        davidreiss666  worldnews     193620  \n",
      "215289            BillTowne  worldnews     215290  \n",
      "137482          readerseven  worldnews     137483  \n",
      "263607             vigorous  worldnews     263608  \n",
      "160561          CoachDamRam  worldnews     160562  \n",
      "38953          davecardwell  worldnews      38954  \n",
      "170699               Noahrv  worldnews     170700  \n",
      "118359             Grankhan  worldnews     118360  \n",
      "157457          LuckyCandy7  worldnews     157458  \n",
      "0                     polar  worldnews          1  \n",
      "404205            BillTowne  worldnews     404206  \n",
      "154101  BackFromTheFuture12  worldnews     154102  \n",
      "333404               conuly  worldnews     333405  \n",
      "82277        Closed_Circuit  worldnews      82278  \n",
      "426587      3xpendableyouth  worldnews     426588  \n",
      "38923       downgoesfrazier  worldnews      38924  \n",
      "153947     FreddieFreelance  worldnews     153948  \n",
      "107624           Ze_Carioca  worldnews     107625  \n",
      "180738     blastkillsdozens  worldnews     180739  \n"
     ]
    }
   ],
   "source": [
    "print(recs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-11-22 00:00:00\n",
      "2016-10-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# 30 days before Recommendation\n",
    "from datetime import datetime, timedelta\n",
    "max_date = df['date_created'].max()\n",
    "start_date = max_date + timedelta(days=-30)\n",
    "print(max_date)\n",
    "print(max_date + timedelta(days=-30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501610\n"
     ]
    }
   ],
   "source": [
    "df['date_created'] = pd.to_datetime(df['date_created'], format='%Y-%m-%d')\n",
    "start_df = df[df['date_created']== start_date]\n",
    "start_idx = start_df['unique_id'][0:1].item() - 1\n",
    "print(start_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function recommends articles from past 30 days\n",
    "def recommend_30days(job_ids, new_job_ids, embeddings, new_embeddings, target_ids, num_recs, vec_dim):\n",
    "    '''\n",
    "    Uses facebook FAISS library to perform L2 similarity search with 100-d vector embeddings\n",
    "    \n",
    "    job_ids: list of jobs_ids, whose indices correspond to embedding indices\n",
    "    embeddings: numpy array of 100-d vectors, whose indices correspond to the indices of job_ids\n",
    "    target_ids: list of target ids\n",
    "    num_recs: the number of recommendations to make\n",
    "    \n",
    "    returns: job dictionary with key = job id and value = embedding\n",
    "    '''\n",
    "    #Get the corresponding embeddings for each target ID\n",
    "    #and convert to numpy array for FAISS\n",
    "    queries = []\n",
    "    for tid in target_ids:\n",
    "        queries.append(embeddings[job_ids.index(tid)])\n",
    "    search_queries = np.asarray(queries)\n",
    "    #Brute force, L2 distance search index.\n",
    "    index = faiss.IndexFlatL2(vec_dim) #build the index\n",
    "    index.add(new_embeddings)\n",
    "    D, I = index.search(search_queries, num_recs)\n",
    "    print(\"Finding the nearest neighbor of the following query: \")\n",
    "    similar_jobs = {}\n",
    "    #index is a list containing indexes corresponding to number of reccomendations requested\n",
    "    for index in I:\n",
    "        for element in index:\n",
    "            similar_jobs.update({new_job_ids[element]: embeddings[element]})\n",
    "            \n",
    "    return similar_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the nearest neighbor of the following query: \n"
     ]
    }
   ],
   "source": [
    "new_embedding_list = embedding_list[start_idx:]\n",
    "new_job_id_list = job_id_list[start_idx:]\n",
    "target_job_ids_list = [1]\n",
    "similar_job_embeddings_30d = recommend_30days(job_id_list, new_job_id_list, embedding_list, new_embedding_list, target_job_ids_list, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_target_df, recs_df_30 = get_rec_desc(similar_job_embeddings_30d, \"unique_id\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time_created date_created  up_votes  down_votes  \\\n",
      "502055    1477355704   2016-10-25      1956           0   \n",
      "502278    1477416451   2016-10-25        16           0   \n",
      "502546    1477488731   2016-10-26         9           0   \n",
      "507189    1479185962   2016-11-15         9           0   \n",
      "504584    1478128730   2016-11-02         8           0   \n",
      "\n",
      "                                                         title  over_18  \\\n",
      "502055      Forty eight dead in Pakistan police academy attack    False   \n",
      "502278          Israeli killed by gunfire from Egypt on border    False   \n",
      "502546  Dozens of civilians abducted and killed in Afghanistan    False   \n",
      "507189  Kashmir clash: Pakistan says India killed seven troops    False   \n",
      "504584           13 killed by cross-border shelling in Kashmir    False   \n",
      "\n",
      "                   author   category  unique_id  \n",
      "502055            xicomen  worldnews     502056  \n",
      "502278              IFRIC  worldnews     502279  \n",
      "502546  middleeastnewsman  worldnews     502547  \n",
      "507189              ELY25  worldnews     507190  \n",
      "504584            Zhaopow  worldnews     504585  \n"
     ]
    }
   ],
   "source": [
    "print(recs_df_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praveen_tf",
   "language": "python",
   "name": "praveen_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
